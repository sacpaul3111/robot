---
#############################################################################
# Ansible Playbook: Robot Framework Test Execution
# Description: Execute all Robot Framework tests with pass/fail summary
# Usage: ansible-playbook run_tests.yml -e TargetHostname=<hostname>
#############################################################################

- name: Execute Robot Framework Tests
  hosts: localhost
  connection: local
  gather_facts: yes
  vars:
    # Default values - can be overridden with -e flag
    robot_project_dir: "{{ playbook_dir }}/.."
    robot_output_dir: "results"

    # TARGET_HOSTNAME - Primary variable used by Robot Framework tests
    # Accept TargetHostname (from Itential) and map to TARGET_HOSTNAME
    target_hostname: "{{ TargetHostname | default(target_hostname) | default('') }}"

    # All credentials are provided via environment variables
    # No need to define them here - they are passed directly to Robot Framework
    # via the environment block in execute_test_suite.yml

    fail_on_test_errors: false

  pre_tasks:
    - name: Display banner
      debug:
        msg:
          - "========================================================"
          - "   GSA Itential Robot Framework - Test Execution"
          - "========================================================"
          - "Project Directory: {{ robot_project_dir }}"
          - "Target Hostname:   {{ target_hostname }}"
          - "Output Directory:  {{ robot_output_dir }}"
          - "========================================================"

    - name: Validate target hostname is provided
      fail:
        msg: |
          ERROR: Target hostname is required!
          Usage: ansible-playbook run_tests.yml -e TargetHostname=<hostname>
          Example: ansible-playbook run_tests.yml -e TargetHostname=alhxvdvitap01
      when: target_hostname == ''

    - name: Validate SSH credentials are provided via environment
      fail:
        msg: |
          ERROR: SSH credentials required!
          Please ensure environment variables are set:
            export SSH_USERNAME=<user>
            export SSH_PASSWORD=<pass>

          Or source credentials file:
            source credentials.env

          Or use wrapper script:
            ./run_tests.sh {{ target_hostname }}
      when: lookup('env', 'SSH_USERNAME') == '' or lookup('env', 'SSH_PASSWORD') == ''

    - name: Create project directory if it doesn't exist
      file:
        path: "{{ robot_project_dir }}"
        state: directory
        mode: '0755'

  tasks:
    - name: Set Python executable to system python
      set_fact:
        python_executable: "python3"

    - name: Display Python executable being used
      debug:
        msg: "Using Python: {{ python_executable }}"

    - name: Check if tests directory exists
      stat:
        path: "{{ robot_project_dir }}/tests"
      register: tests_dir_stat

    - name: Fail if tests directory does not exist
      fail:
        msg: "Tests directory not found: {{ robot_project_dir }}/tests"
      when: not tests_dir_stat.stat.exists

    - name: Create output directory
      file:
        path: "{{ robot_project_dir }}/{{ robot_output_dir }}"
        state: directory
        mode: '0755'

    - name: Find all test suite directories
      find:
        paths: "{{ robot_project_dir }}/tests"
        file_type: directory
        patterns: 'test*_*'
      register: test_directories

    - name: Display found test suites
      debug:
        msg: "Found {{ test_directories.files | length }} test suite(s)"

    - name: Initialize test results tracking
      set_fact:
        test_results: []
        all_output_files: []
        total_tests: 0
        passed_tests: 0
        failed_tests: 0

    - name: Execute each test suite
      include_tasks: execute_test_suite.yml
      loop: "{{ test_directories.files | sort(attribute='path') }}"
      loop_control:
        loop_var: test_dir

    - name: Create consolidated reports using rebot
      command: >
        {{ python_executable }} -m robot.rebot
        --outputdir {{ robot_project_dir }}/{{ robot_output_dir }}
        --output all_output.xml
        --log all_log.html
        --report all_report.html
        {{ all_output_files | join(' ') }}
      args:
        chdir: "{{ robot_project_dir }}"
      register: rebot_result
      ignore_errors: yes
      when: all_output_files | length > 0

    - name: Check if consolidated report was created
      stat:
        path: "{{ robot_project_dir }}/{{ robot_output_dir }}/all_report.html"
      register: consolidated_report_stat

    - name: Parse consolidated output.xml for final results
      xml:
        path: "{{ robot_project_dir }}/{{ robot_output_dir }}/all_output.xml"
        xpath: /robot/statistics/total/stat
        content: attribute
      register: final_statistics
      when: consolidated_report_stat.stat.exists
      ignore_errors: yes

    - name: Extract pass/fail counts from consolidated results
      set_fact:
        total_tests_final: "{{ final_statistics.matches[0].stat.pass | default('0') | int + final_statistics.matches[0].stat.fail | default('0') | int }}"
        passed_tests_final: "{{ final_statistics.matches[0].stat.pass | default('0') | int }}"
        failed_tests_final: "{{ final_statistics.matches[0].stat.fail | default('0') | int }}"
      when:
        - consolidated_report_stat.stat.exists
        - final_statistics.matches is defined
        - final_statistics.matches | length > 0
      ignore_errors: yes

    - name: Set final test status
      set_fact:
        all_tests_passed: "{{ (failed_tests_final | default(failed_tests) | int) == 0 and (total_tests_final | default(total_tests) | int) > 0 }}"
        results_directory: "{{ robot_project_dir }}/{{ robot_output_dir }}"
        consolidated_log: "{{ robot_project_dir }}/{{ robot_output_dir }}/all_log.html"
        consolidated_report: "{{ robot_project_dir }}/{{ robot_output_dir }}/all_report.html"
        total_count: "{{ total_tests_final | default(total_tests) }}"
        passed_count: "{{ passed_tests_final | default(passed_tests) }}"
        failed_count: "{{ failed_tests_final | default(failed_tests) }}"
        nexus_artifacts_url: "https://nexus.company.com/repository/robot-framework-artifacts/{{ target_hostname }}/{{ ansible_date_time.iso8601 | regex_replace('[:]', '-') }}"

  post_tasks:
    - name: Display test execution summary
      debug:
        msg:
          - "========================================================"
          - "           TEST EXECUTION SUMMARY"
          - "========================================================"
          - "Total Tests:    {{ total_count }}"
          - "Passed Tests:   {{ passed_count }}"
          - "Failed Tests:   {{ failed_count }}"
          - "========================================================"
          - "Overall Status: {{ 'PASSED ✅' if all_tests_passed else 'FAILED ❌' }}"
          - "========================================================"
          - ""
          - "Results Location:"
          - "  Directory:    {{ results_directory }}"
          - "  Log:          {{ consolidated_log }}"
          - "  Report:       {{ consolidated_report }}"
          - ""
          - "Artifacts URL (Nexus OSS):"
          - "  {{ nexus_artifacts_url }}"
          - "========================================================"

    - name: Display individual test suite results
      debug:
        msg: "{{ test_results }}"
      when: test_results | length > 0

    - name: Save test summary to file
      copy:
        content: |
          ========================================================
          GSA Itential Robot Framework - Test Execution Summary
          ========================================================
          Execution Date: {{ ansible_date_time.iso8601 }}
          Target Hostname: {{ target_hostname }}

          ========================================================
          RESULTS SUMMARY
          ========================================================
          Total Tests:    {{ total_count }}
          Passed Tests:   {{ passed_count }}
          Failed Tests:   {{ failed_count }}
          Overall Status: {{ 'PASSED' if all_tests_passed else 'FAILED' }}

          ========================================================
          INDIVIDUAL TEST SUITES
          ========================================================
          {% for result in test_results %}
          {{ result }}
          {% endfor %}

          ========================================================
          RESULTS LOCATION
          ========================================================
          Directory:  {{ results_directory }}
          Log:        {{ consolidated_log }}
          Report:     {{ consolidated_report }}

          ========================================================
          ARTIFACTS URL (NEXUS OSS)
          ========================================================
          {{ nexus_artifacts_url }}
          ========================================================
        dest: "{{ robot_project_dir }}/{{ robot_output_dir }}/TEST_SUMMARY.txt"
        mode: '0644'

    - name: Display summary file location
      debug:
        msg: "Test summary saved to: {{ robot_project_dir }}/{{ robot_output_dir }}/TEST_SUMMARY.txt"

    - name: Fail playbook if tests failed and fail_on_test_errors is true
      fail:
        msg: |
          ❌ TEST EXECUTION FAILED ❌
          {{ failed_count }} test(s) failed
          Check reports at: {{ results_directory }}
      when:
        - not all_tests_passed
        - fail_on_test_errors | bool
